{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-03T01:32:45.166600Z","iopub.execute_input":"2022-05-03T01:32:45.166920Z","iopub.status.idle":"2022-05-03T01:32:45.186868Z","shell.execute_reply.started":"2022-05-03T01:32:45.166884Z","shell.execute_reply":"2022-05-03T01:32:45.185921Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.datasets import imdb\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils.np_utils import to_categorical\nfrom keras.callbacks import EarlyStopping\nfrom keras.layers import Dropout\nimport re\nfrom nltk.corpus import stopwords\nfrom nltk import word_tokenize","metadata":{"execution":{"iopub.status.busy":"2022-05-03T01:32:45.852519Z","iopub.execute_input":"2022-05-03T01:32:45.852818Z","iopub.status.idle":"2022-05-03T01:32:45.859784Z","shell.execute_reply.started":"2022-05-03T01:32:45.852771Z","shell.execute_reply":"2022-05-03T01:32:45.859139Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"def clean_data(text):\n    text = text.lower()\n    text = REPLACE_BY_SPACE_RE.sub(' ', text) \n    text = BAD_SYMBOLS_RE.sub('', text)\n    text = text.replace('x', '')\n    text = ' '.join(word for word in text.split() if word not in STOPWORDS)\n    return text","metadata":{"execution":{"iopub.status.busy":"2022-05-03T01:41:14.715198Z","iopub.execute_input":"2022-05-03T01:41:14.715922Z","iopub.status.idle":"2022-05-03T01:41:14.721029Z","shell.execute_reply.started":"2022-05-03T01:41:14.715874Z","shell.execute_reply":"2022-05-03T01:41:14.720110Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/nlp-getting-started/train.csv\")\ndf = df.drop(['id', 'keyword', 'location'], axis = 1)\ndf = df.reset_index(drop=True)\nREPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\nBAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\nSTOPWORDS = set(stopwords.words('english'))\ndf['text'] = df['text'].apply(clean_data)\ndf['text'] = df['text'].str.replace('\\d+', '')\ndf","metadata":{"execution":{"iopub.status.busy":"2022-05-03T01:32:49.440564Z","iopub.execute_input":"2022-05-03T01:32:49.441472Z","iopub.status.idle":"2022-05-03T01:32:49.559733Z","shell.execute_reply.started":"2022-05-03T01:32:49.441421Z","shell.execute_reply":"2022-05-03T01:32:49.558936Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"max_words = 40000\nmax_seq_len = 200\nembed_size = 100\n\ntokenizer = Tokenizer(num_words=max_words, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\ntokenizer.fit_on_texts(df['text'].values)\nword_index = tokenizer.word_index\nprint('Number of Unique Tokens:', len(word_index))\n\nX = tokenizer.texts_to_sequences(df['text'].values)\nX = pad_sequences(X, maxlen=max_seq_len)\n\ny = np.array(df['target'])\n\nprint(\"X:\", X)\nprint(\"y:\", y)","metadata":{"execution":{"iopub.status.busy":"2022-05-03T01:35:07.687824Z","iopub.execute_input":"2022-05-03T01:35:07.688104Z","iopub.status.idle":"2022-05-03T01:35:07.976476Z","shell.execute_reply.started":"2022-05-03T01:35:07.688076Z","shell.execute_reply":"2022-05-03T01:35:07.975551Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, Y_train, Y_test = train_test_split(X,y, test_size = 0.30, random_state = 42)\nprint(X_train.shape,Y_train.shape)\nprint(X_test.shape,Y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-05-03T01:35:25.314572Z","iopub.execute_input":"2022-05-03T01:35:25.315468Z","iopub.status.idle":"2022-05-03T01:35:25.326351Z","shell.execute_reply.started":"2022-05-03T01:35:25.315412Z","shell.execute_reply":"2022-05-03T01:35:25.325681Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"model=tf.keras.Sequential()\n\n# First Layer\nmodel.add(tf.keras.layers.Embedding(max_words, embed_size, input_shape=(X_train.shape[1],)))\n\n# Hidden Layer\nmodel.add(tf.keras.layers.LSTM(units=128, activation='tanh'))\n\n# Output Layer\nmodel.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-05-03T01:36:53.376356Z","iopub.execute_input":"2022-05-03T01:36:53.377233Z","iopub.status.idle":"2022-05-03T01:36:53.641256Z","shell.execute_reply.started":"2022-05-03T01:36:53.377192Z","shell.execute_reply":"2022-05-03T01:36:53.640394Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer='rmsprop', loss='mean_squared_error', metrics=['accuracy'])\nmodel.fit(X_train, Y_train, epochs=10, batch_size=128)\n\ntest_loss, test_accuracy = model.evaluate(X_test, Y_test)\n\nprint(\"Test accuracy: {}\".format(test_accuracy))","metadata":{"execution":{"iopub.status.busy":"2022-05-03T01:15:36.607141Z","iopub.execute_input":"2022-05-03T01:15:36.607412Z","iopub.status.idle":"2022-05-03T01:18:39.385665Z","shell.execute_reply.started":"2022-05-03T01:15:36.607384Z","shell.execute_reply":"2022-05-03T01:18:39.385117Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"train_acc = [0.6789, 0.6690, 0.7403, 0.9129, 0.9445, 0.9621, 0.9762, 0.9842, 0.9645, 0.9923]\ntrain_loss = [.2083, 0.3089, 0.2367, 0.0677, 0.0457, 0.0312, 0.0207, 0.0137, 0.0329, 0.0069]","metadata":{"execution":{"iopub.status.busy":"2022-05-03T01:43:31.784524Z","iopub.execute_input":"2022-05-03T01:43:31.784838Z","iopub.status.idle":"2022-05-03T01:43:31.789845Z","shell.execute_reply.started":"2022-05-03T01:43:31.784803Z","shell.execute_reply":"2022-05-03T01:43:31.788818Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"plt.plot(range(10), train_acc, label=\"Accuracy\")\nplt.plot(range(10), train_loss, label=\"Loss\")\nplt.title(\"Accuracy and Loss of Train Data by Epoch\")\nplt.xlabel(\"Epoch\")\nplt.legend()","metadata":{"execution":{"iopub.status.busy":"2022-05-03T01:45:02.781151Z","iopub.execute_input":"2022-05-03T01:45:02.781450Z","iopub.status.idle":"2022-05-03T01:45:02.988985Z","shell.execute_reply.started":"2022-05-03T01:45:02.781414Z","shell.execute_reply":"2022-05-03T01:45:02.988042Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}